{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Skimlit",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/149189/Project-SkimLit/blob/main/Skimlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:52.633836Z",
          "iopub.execute_input": "2024-09-03T10:14:52.634675Z",
          "iopub.status.idle": "2024-09-03T10:14:52.641213Z",
          "shell.execute_reply.started": "2024-09-03T10:14:52.63463Z",
          "shell.execute_reply": "2024-09-03T10:14:52.640148Z"
        },
        "trusted": true,
        "id": "NDmvtks0ajrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct.git\n",
        "!ls pubmed-rct"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:52.643009Z",
          "iopub.execute_input": "2024-09-03T10:14:52.643356Z",
          "iopub.status.idle": "2024-09-03T10:14:55.134869Z",
          "shell.execute_reply.started": "2024-09-03T10:14:52.643311Z",
          "shell.execute_reply": "2024-09-03T10:14:55.133649Z"
        },
        "trusted": true,
        "id": "YM1PdSuRajrH",
        "outputId": "be92e934-9c33-4a6b-bfdf-e4705658e9a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "fatal: destination path 'pubmed-rct' already exists and is not an empty directory.\nPubMed_200k_RCT\nPubMed_200k_RCT_numbers_replaced_with_at_sign\nPubMed_20k_RCT\nPubMed_20k_RCT_numbers_replaced_with_at_sign\nREADME.md\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = \"/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:55.136383Z",
          "iopub.execute_input": "2024-09-03T10:14:55.136725Z",
          "iopub.status.idle": "2024-09-03T10:14:55.141919Z",
          "shell.execute_reply.started": "2024-09-03T10:14:55.136687Z",
          "shell.execute_reply": "2024-09-03T10:14:55.140825Z"
        },
        "trusted": true,
        "id": "kHNvNa1eajrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:55.14411Z",
          "iopub.execute_input": "2024-09-03T10:14:55.144405Z",
          "iopub.status.idle": "2024-09-03T10:14:55.154064Z",
          "shell.execute_reply.started": "2024-09-03T10:14:55.144373Z",
          "shell.execute_reply": "2024-09-03T10:14:55.153112Z"
        },
        "trusted": true,
        "id": "iiJMY-XNajrI",
        "outputId": "8b033526-0de4-4382-c133-1ead65074655"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 103,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/dev.txt',\n '/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/test.txt',\n '/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.zip',\n '/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.txt']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lines(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:55.155132Z",
          "iopub.execute_input": "2024-09-03T10:14:55.155414Z",
          "iopub.status.idle": "2024-09-03T10:14:55.164789Z",
          "shell.execute_reply.started": "2024-09-03T10:14:55.155382Z",
          "shell.execute_reply": "2024-09-03T10:14:55.163952Z"
        },
        "trusted": true,
        "id": "PIHVYc2DajrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Specify the path to the zip file\n",
        "zip_file_path = '/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign/train.zip'\n",
        "\n",
        "# Specify the directory to extract to (optional)\n",
        "extract_dir = '/kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign'  # You can specify a different directory or leave it as default to extract in the current directory\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Open the zip file and extract its contents\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"Extraction completed. Files extracted to: {extract_dir}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:55.166012Z",
          "iopub.execute_input": "2024-09-03T10:14:55.166321Z",
          "iopub.status.idle": "2024-09-03T10:14:57.510512Z",
          "shell.execute_reply.started": "2024-09-03T10:14:55.166288Z",
          "shell.execute_reply": "2024-09-03T10:14:57.509568Z"
        },
        "trusted": true,
        "id": "7teCAxg-ajrJ",
        "outputId": "63f79559-ed6e-470e-95e8-2fd9184d7902"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Extraction completed. Files extracted to: /kaggle/working/pubmed-rct/PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines = get_lines(data_dir + \"train.txt\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:57.511737Z",
          "iopub.execute_input": "2024-09-03T10:14:57.512069Z",
          "iopub.status.idle": "2024-09-03T10:14:58.655252Z",
          "shell.execute_reply.started": "2024-09-03T10:14:57.512035Z",
          "shell.execute_reply": "2024-09-03T10:14:58.654208Z"
        },
        "trusted": true,
        "id": "heaR_Kj9ajrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lines[:20]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:58.656984Z",
          "iopub.execute_input": "2024-09-03T10:14:58.657303Z",
          "iopub.status.idle": "2024-09-03T10:14:58.665397Z",
          "shell.execute_reply.started": "2024-09-03T10:14:58.65727Z",
          "shell.execute_reply": "2024-09-03T10:14:58.664448Z"
        },
        "trusted": true,
        "id": "St-qLl4RajrJ",
        "outputId": "38e8fce6-ec9b-4212-ac56-6e2609e112f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 107,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['###24491034\\n',\n 'BACKGROUND\\tThe emergence of HIV as a chronic condition means that people living with HIV are required to take more responsibility for the self-management of their condition , including making physical , emotional and social adjustments .\\n',\n 'BACKGROUND\\tThis paper describes the design and evaluation of Positive Outlook , an online program aiming to enhance the self-management skills of gay men living with HIV .\\n',\n 'METHODS\\tThis study is designed as a randomised controlled trial in which men living with HIV in Australia will be assigned to either an intervention group or usual care control group .\\n',\n \"METHODS\\tThe intervention group will participate in the online group program ` Positive Outlook ' .\\n\",\n 'METHODS\\tThe program is based on self-efficacy theory and uses a self-management approach to enhance skills , confidence and abilities to manage the psychosocial issues associated with HIV in daily life .\\n',\n 'METHODS\\tParticipants will access the program for a minimum of @ minutes per week over seven weeks .\\n',\n 'METHODS\\tPrimary outcomes are domain specific self-efficacy , HIV related quality of life , and outcomes of health education .\\n',\n 'METHODS\\tSecondary outcomes include : depression , anxiety and stress ; general health and quality of life ; adjustment to HIV ; and social support .\\n',\n 'METHODS\\tData collection will take place at baseline , completion of the intervention ( or eight weeks post randomisation ) and at @ week follow-up .\\n',\n 'CONCLUSIONS\\tResults of the Positive Outlook study will provide information regarding the effectiveness of online group programs improving health related outcomes for men living with HIV .\\n',\n 'BACKGROUND\\tACTRN@ .\\n',\n '\\n',\n '###20497432\\n',\n 'BACKGROUND\\tThe aim of this study was to evaluate the efficacy , safety and complications of orbital steroid injection versus oral steroid therapy in the management of thyroid-related ophthalmopathy .\\n',\n 'METHODS\\tA total of @ patients suffering from thyroid ophthalmopathy were included in this study .\\n',\n 'METHODS\\tPatients were randomized into two groups : group I included @ patients treated with oral prednisolone and group II included @ patients treated with peribulbar triamcinolone orbital injection .\\n',\n 'METHODS\\tOnly @ patients in both groups ( @ female and @ male ) completed the study .\\n',\n 'RESULTS\\tBoth groups showed improvement in symptoms and in clinical evidence of inflammation with improvement of eye movement and proptosis in most cases .\\n',\n 'RESULTS\\tMean exophthalmometry value before treatment was @ @ mm that decreased to @ @ mm in group I , compared with @ @ mm that decreased to @ @ mm in group II .\\n']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text_with_line_numbers(filename):\n",
        "  input_lines = get_lines(filename)\n",
        "  abstract_lines = \"\"\n",
        "  abstract_samples = []\n",
        "\n",
        "\n",
        "  # Loop through each line in target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"): # check to see if line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset abstract string\n",
        "    elif line.isspace(): # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines() # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create empty dict to store data from line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower() # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in the abstract?\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are in the abstract? (start from 0)\n",
        "        abstract_samples.append(line_data) # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled sentence\n",
        "      abstract_lines += line\n",
        "\n",
        "  return abstract_samples\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:58.666535Z",
          "iopub.execute_input": "2024-09-03T10:14:58.66701Z",
          "iopub.status.idle": "2024-09-03T10:14:58.676784Z",
          "shell.execute_reply.started": "2024-09-03T10:14:58.666967Z",
          "shell.execute_reply": "2024-09-03T10:14:58.675849Z"
        },
        "trusted": true,
        "id": "jHcsjU5SajrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir + \"dev.txt\") # dev is another name for validation set\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir + \"test.txt\")\n",
        "len(train_samples), len(val_samples), len(test_samples)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:14:58.680602Z",
          "iopub.execute_input": "2024-09-03T10:14:58.680901Z",
          "iopub.status.idle": "2024-09-03T10:15:05.980551Z",
          "shell.execute_reply.started": "2024-09-03T10:14:58.680857Z",
          "shell.execute_reply": "2024-09-03T10:15:05.979577Z"
        },
        "trusted": true,
        "id": "VlhHglLEajrK",
        "outputId": "ac68fab5-b37b-4770-d07d-55978591f03d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "CPU times: user 6.18 s, sys: 1.08 s, total: 7.26 s\nWall time: 7.29 s\n",
          "output_type": "stream"
        },
        {
          "execution_count": 109,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2211861, 28932, 29493)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)\n",
        "train_df.head(14)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:05.981722Z",
          "iopub.execute_input": "2024-09-03T10:15:05.982061Z",
          "iopub.status.idle": "2024-09-03T10:15:09.933988Z",
          "shell.execute_reply.started": "2024-09-03T10:15:05.982027Z",
          "shell.execute_reply": "2024-09-03T10:15:09.932997Z"
        },
        "trusted": true,
        "id": "aGGDhzUAajrK",
        "outputId": "6d5a73c4-c022-4a3c-8bdd-c1a032ec7d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 110,
          "output_type": "execute_result",
          "data": {
            "text/plain": "         target                                               text  \\\n0    BACKGROUND  the emergence of hiv as a chronic condition me...   \n1    BACKGROUND  this paper describes the design and evaluation...   \n2       METHODS  this study is designed as a randomised control...   \n3       METHODS  the intervention group will participate in the...   \n4       METHODS  the program is based on self-efficacy theory a...   \n5       METHODS  participants will access the program for a min...   \n6       METHODS  primary outcomes are domain specific self-effi...   \n7       METHODS  secondary outcomes include : depression , anxi...   \n8       METHODS  data collection will take place at baseline , ...   \n9   CONCLUSIONS  results of the positive outlook study will pro...   \n10   BACKGROUND                                           actrn@ .   \n11   BACKGROUND  the aim of this study was to evaluate the effi...   \n12      METHODS  a total of @ patients suffering from thyroid o...   \n13      METHODS  patients were randomized into two groups : gro...   \n\n    line_number  total_lines  \n0             0           10  \n1             1           10  \n2             2           10  \n3             3           10  \n4             4           10  \n5             5           10  \n6             6           10  \n7             7           10  \n8             8           10  \n9             9           10  \n10           10           10  \n11            0           11  \n12            1           11  \n13            2           11  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>target</th>\n      <th>text</th>\n      <th>line_number</th>\n      <th>total_lines</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BACKGROUND</td>\n      <td>the emergence of hiv as a chronic condition me...</td>\n      <td>0</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BACKGROUND</td>\n      <td>this paper describes the design and evaluation...</td>\n      <td>1</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>METHODS</td>\n      <td>this study is designed as a randomised control...</td>\n      <td>2</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>METHODS</td>\n      <td>the intervention group will participate in the...</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>METHODS</td>\n      <td>the program is based on self-efficacy theory a...</td>\n      <td>4</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>METHODS</td>\n      <td>participants will access the program for a min...</td>\n      <td>5</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>METHODS</td>\n      <td>primary outcomes are domain specific self-effi...</td>\n      <td>6</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>METHODS</td>\n      <td>secondary outcomes include : depression , anxi...</td>\n      <td>7</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>METHODS</td>\n      <td>data collection will take place at baseline , ...</td>\n      <td>8</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>CONCLUSIONS</td>\n      <td>results of the positive outlook study will pro...</td>\n      <td>9</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>BACKGROUND</td>\n      <td>actrn@ .</td>\n      <td>10</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BACKGROUND</td>\n      <td>the aim of this study was to evaluate the effi...</td>\n      <td>0</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>METHODS</td>\n      <td>a total of @ patients suffering from thyroid o...</td>\n      <td>1</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>METHODS</td>\n      <td>patients were randomized into two groups : gro...</td>\n      <td>2</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()\n",
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:09.935401Z",
          "iopub.execute_input": "2024-09-03T10:15:09.935833Z",
          "iopub.status.idle": "2024-09-03T10:15:10.040761Z",
          "shell.execute_reply.started": "2024-09-03T10:15:09.935785Z",
          "shell.execute_reply": "2024-09-03T10:15:10.039816Z"
        },
        "trusted": true,
        "id": "OEEzzdrLajrK",
        "outputId": "7063f6f0-6b3c-4fa3-a57d-708252bc7dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 111,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(2211861, 28932, 29493)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  from sklearn.preprocessing import OneHotEncoder\n",
        "  one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "  train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "  val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "  test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1, 1))\n",
        "\n",
        "  # Check what training labels look like\n",
        "  train_labels_one_hot"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:10.042689Z",
          "iopub.execute_input": "2024-09-03T10:15:10.043144Z",
          "iopub.status.idle": "2024-09-03T10:15:10.950882Z",
          "shell.execute_reply.started": "2024-09-03T10:15:10.043098Z",
          "shell.execute_reply": "2024-09-03T10:15:10.949939Z"
        },
        "trusted": true,
        "id": "1RChMtxgajrK",
        "outputId": "87cc1fd1-be0d-447c-8b51-6f556dbac58a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 112,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       ...,\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1.]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())\n",
        "\n",
        "# Check what training labels look like\n",
        "train_labels_encoded"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:10.952292Z",
          "iopub.execute_input": "2024-09-03T10:15:10.952712Z",
          "iopub.status.idle": "2024-09-03T10:15:11.508333Z",
          "shell.execute_reply.started": "2024-09-03T10:15:10.952665Z",
          "shell.execute_reply": "2024-09-03T10:15:11.507442Z"
        },
        "trusted": true,
        "id": "e_OzBt4xajrK",
        "outputId": "d5d61467-2712-460f-e5e3-c5b1e84fb875"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 113,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([0, 0, 2, ..., 4, 4, 4])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:11.509909Z",
          "iopub.execute_input": "2024-09-03T10:15:11.51036Z",
          "iopub.status.idle": "2024-09-03T10:15:11.517725Z",
          "shell.execute_reply.started": "2024-09-03T10:15:11.510312Z",
          "shell.execute_reply": "2024-09-03T10:15:11.516664Z"
        },
        "trusted": true,
        "id": "hLKCP55rajrL",
        "outputId": "4eed9daf-1c42-44c5-f5b2-52fcce8c6561"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 114,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(5,\n array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n       dtype=object))"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:11.518951Z",
          "iopub.execute_input": "2024-09-03T10:15:11.519316Z",
          "iopub.status.idle": "2024-09-03T10:15:11.527408Z",
          "shell.execute_reply.started": "2024-09-03T10:15:11.519283Z",
          "shell.execute_reply": "2024-09-03T10:15:11.526486Z"
        },
        "trusted": true,
        "id": "lSHcD7t1ajrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How long is each sentence on average?\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len # return average sentence length (in tokens)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:11.528956Z",
          "iopub.execute_input": "2024-09-03T10:15:11.529362Z",
          "iopub.status.idle": "2024-09-03T10:15:15.206472Z",
          "shell.execute_reply.started": "2024-09-03T10:15:11.52931Z",
          "shell.execute_reply": "2024-09-03T10:15:15.205498Z"
        },
        "trusted": true,
        "id": "sUuN1xOjajrL",
        "outputId": "04d7914d-40f0-4e39-e70b-06022a470a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 116,
          "output_type": "execute_result",
          "data": {
            "text/plain": "26.229355280462922"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How long of a sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:15.207699Z",
          "iopub.execute_input": "2024-09-03T10:15:15.208046Z",
          "iopub.status.idle": "2024-09-03T10:15:15.411627Z",
          "shell.execute_reply.started": "2024-09-03T10:15:15.208012Z",
          "shell.execute_reply": "2024-09-03T10:15:15.410624Z"
        },
        "trusted": true,
        "id": "01PbM0AEajrL",
        "outputId": "c2e16106-57f2-451f-b76a-2dfd04266b90"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 117,
          "output_type": "execute_result",
          "data": {
            "text/plain": "54"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_tokens = 68000"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:15.413137Z",
          "iopub.execute_input": "2024-09-03T10:15:15.413888Z",
          "iopub.status.idle": "2024-09-03T10:15:15.418165Z",
          "shell.execute_reply.started": "2024-09-03T10:15:15.413841Z",
          "shell.execute_reply": "2024-09-03T10:15:15.417202Z"
        },
        "trusted": true,
        "id": "f2beyXfqajrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create text vectorizer\n",
        "\n",
        "# After TensorFlow 2.6\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "# Before TensorFlow 2.6\n",
        "# from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # number of words in vocabulary\n",
        "                                    output_sequence_length=55) # desired output length of vectorized sequences"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:15.419544Z",
          "iopub.execute_input": "2024-09-03T10:15:15.420306Z",
          "iopub.status.idle": "2024-09-03T10:15:15.438019Z",
          "shell.execute_reply.started": "2024-09-03T10:15:15.420272Z",
          "shell.execute_reply": "2024-09-03T10:15:15.437128Z"
        },
        "trusted": true,
        "id": "X1nCuhZUajrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adapt text vectorizer to training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:15.439277Z",
          "iopub.execute_input": "2024-09-03T10:15:15.440075Z",
          "iopub.status.idle": "2024-09-03T10:15:33.580771Z",
          "shell.execute_reply.started": "2024-09-03T10:15:15.440029Z",
          "shell.execute_reply": "2024-09-03T10:15:33.579946Z"
        },
        "trusted": true,
        "id": "6cZfniNqajrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out text vectorizer\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text:\\n{text_vectorizer([target_sentence])}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:33.706966Z",
          "iopub.execute_input": "2024-09-03T10:15:33.707371Z",
          "iopub.status.idle": "2024-09-03T10:15:33.726745Z",
          "shell.execute_reply.started": "2024-09-03T10:15:33.707332Z",
          "shell.execute_reply": "2024-09-03T10:15:33.725811Z"
        },
        "trusted": true,
        "id": "sOqzkIGNajrL",
        "outputId": "b7e52c7f-ab15-4d52-8308-a0c73b1005dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Text:\ndepressive symptoms were negatively related to cortisol levels ( = -@ , p = @ ) but were positively related to rate of change in cortisol ( = @ , p = @ ) .\n\nLength of text: 35\n\nVectorized text:\n[[ 830  134    9 2835  353    6 1139   77   14   65    9 1851  353    6\n    68    3  148    5 1139   14    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many words in our training vocabulary?\n",
        "rct_200k_text_vocab = text_vectorizer.get_vocabulary()\n",
        "print(f\"Number of words in vocabulary: {len(rct_200k_text_vocab)}\"),\n",
        "print(f\"Most common words in the vocabulary: {rct_200k_text_vocab[:5]}\")\n",
        "print(f\"Least common words in the vocabulary: {rct_200k_text_vocab[-5:]}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:33.728141Z",
          "iopub.execute_input": "2024-09-03T10:15:33.728886Z",
          "iopub.status.idle": "2024-09-03T10:15:34.024373Z",
          "shell.execute_reply.started": "2024-09-03T10:15:33.72884Z",
          "shell.execute_reply": "2024-09-03T10:15:34.023556Z"
        },
        "trusted": true,
        "id": "vWvMgmjoajrM",
        "outputId": "d30cb1c3-7cb0-404c-a38a-5cbcaab3ee93"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Number of words in vocabulary: 68000\nMost common words in the vocabulary: ['', '[UNK]', 'the', 'of', 'and']\nLeast common words in the vocabulary: ['resite', 'residentmonths', 'rescueeligible', 'rescheduling', 'resc']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_200k_text_vocab), # length of vocabulary\n",
        "                               output_dim=128, # Note: different embedding sizes result in drastically different numbers of parameters to train\n",
        "                               # Use masking to handle variable sequence lengths (save space)\n",
        "                               mask_zero=True,\n",
        "                               name=\"token_embedding\")\n",
        "\n",
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n{vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n{embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:34.026044Z",
          "iopub.execute_input": "2024-09-03T10:15:34.026361Z",
          "iopub.status.idle": "2024-09-03T10:15:34.053327Z",
          "shell.execute_reply.started": "2024-09-03T10:15:34.026327Z",
          "shell.execute_reply": "2024-09-03T10:15:34.052413Z"
        },
        "trusted": true,
        "id": "WTspoTDkajrM",
        "outputId": "95cdd132-ada6-4573-f7f8-140cabc49179"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Sentence before vectorization:\ndepressive symptoms were negatively related to cortisol levels ( = -@ , p = @ ) but were positively related to rate of change in cortisol ( = @ , p = @ ) .\n\nSentence after vectorization (before embedding):\n[[ 830  134    9 2835  353    6 1139   77   14   65    9 1851  353    6\n    68    3  148    5 1139   14    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n     0    0    0    0    0    0    0    0    0    0    0    0    0]]\n\nSentence after embedding:\n[[[ 0.02714041 -0.01843305  0.00489082 ...  0.0496169  -0.00711782\n    0.00312172]\n  [-0.04594306 -0.00686098  0.00467074 ...  0.02050381  0.03271338\n    0.02299733]\n  [ 0.04309971 -0.04123069  0.01233436 ... -0.00108576  0.04583368\n   -0.03891801]\n  ...\n  [-0.03709999 -0.04539178  0.03348866 ... -0.0291046   0.00660739\n   -0.01398404]\n  [-0.03709999 -0.04539178  0.03348866 ... -0.0291046   0.00660739\n   -0.01398404]\n  [-0.03709999 -0.04539178  0.03348866 ... -0.0291046   0.00660739\n   -0.01398404]]]\n\nEmbedded sentence shape: (1, 55, 128)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn our data into TensorFlow Datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:34.054716Z",
          "iopub.execute_input": "2024-09-03T10:15:34.055061Z",
          "iopub.status.idle": "2024-09-03T10:15:43.501247Z",
          "shell.execute_reply.started": "2024-09-03T10:15:34.055026Z",
          "shell.execute_reply": "2024-09-03T10:15:43.500236Z"
        },
        "trusted": true,
        "id": "lpXRzI4KajrM",
        "outputId": "e12fa25c-63ff-4670-90ac-a042d5a50dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 124,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(5,), dtype=tf.float64, name=None))>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:43.503709Z",
          "iopub.execute_input": "2024-09-03T10:15:43.50407Z",
          "iopub.status.idle": "2024-09-03T10:15:43.51944Z",
          "shell.execute_reply.started": "2024-09-03T10:15:43.504035Z",
          "shell.execute_reply": "2024-09-03T10:15:43.518465Z"
        },
        "trusted": true,
        "id": "ZoXsVtVpajrM",
        "outputId": "249ffc5e-d360-4179-c8ba-f7382f906777"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 125,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None, 5), dtype=tf.float64, name=None))>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained TensorFlow Hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        trainable=False,\n",
        "                                        name=\"universal_sentence_encoder\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:43.520606Z",
          "iopub.execute_input": "2024-09-03T10:15:43.520902Z",
          "iopub.status.idle": "2024-09-03T10:15:48.760572Z",
          "shell.execute_reply.started": "2024-09-03T10:15:43.52087Z",
          "shell.execute_reply": "2024-09-03T10:15:48.759659Z"
        },
        "trusted": true,
        "id": "B2zeciw5ajrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out the embedding on a random sentence\n",
        "random_training_sentence = random.choice(train_sentences)\n",
        "print(f\"Random training sentence:\\n{random_training_sentence}\\n\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_training_sentence])\n",
        "print(f\"Sentence after embedding:\\n{use_embedded_sentence[0][:30]} (truncated output)...\\n\")\n",
        "print(f\"Length of sentence embedding:\\n{len(use_embedded_sentence[0])}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:48.768343Z",
          "iopub.execute_input": "2024-09-03T10:15:48.76868Z",
          "iopub.status.idle": "2024-09-03T10:15:49.094237Z",
          "shell.execute_reply.started": "2024-09-03T10:15:48.768647Z",
          "shell.execute_reply": "2024-09-03T10:15:49.093281Z"
        },
        "trusted": true,
        "id": "wzaothWdajrM",
        "outputId": "427dd23a-266f-4e16-8a4c-81fed9078b2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Random training sentence:\nin the hydroxyethyl starch group and the lactated ringer 's group , the patients received an infusion of @ ml of @ % hydroxyethyl starch solution or @ ml of lactated ringer 's solution over @ min after the spinal block .\n\nSentence after embedding:\n[ 0.00658508  0.00788666 -0.04127871 -0.03084221 -0.06106483 -0.01730666\n  0.03833698 -0.06361872 -0.06264473 -0.04886368  0.06822549  0.06833437\n  0.04794074  0.05361527 -0.04684861 -0.04926032 -0.07916574  0.04252292\n -0.06280175  0.04067573  0.07637423  0.02837753  0.03537761 -0.01420903\n  0.00650351  0.05697114 -0.04417526  0.0082927   0.02474834  0.06094695] (truncated output)...\n\nLength of sentence embedding:\n512\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:49.095555Z",
          "iopub.execute_input": "2024-09-03T10:15:49.095862Z",
          "iopub.status.idle": "2024-09-03T10:15:50.521951Z",
          "shell.execute_reply.started": "2024-09-03T10:15:49.09583Z",
          "shell.execute_reply": "2024-09-03T10:15:50.520426Z"
        },
        "trusted": true,
        "id": "DPkbtQ4OajrM",
        "outputId": "1fd67a0b-a648-4e6a-a4be-e2e260753ba9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "--2024-09-03 10:15:50--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: 'helper_functions.py.1'\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n\n2024-09-03 10:15:50 (77.0 MB/s) - 'helper_functions.py.1' saved [10246/10246]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import calculate_results helper function\n",
        "from helper_functions import calculate_results"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:50.524301Z",
          "iopub.execute_input": "2024-09-03T10:15:50.524851Z",
          "iopub.status.idle": "2024-09-03T10:15:50.532395Z",
          "shell.execute_reply.started": "2024-09-03T10:15:50.524788Z",
          "shell.execute_reply": "2024-09-03T10:15:50.530987Z"
        },
        "trusted": true,
        "id": "ZfBqjvIbajrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Test splitting non-character-level sequence into characters\n",
        "split_chars(random_training_sentence)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:50.534556Z",
          "iopub.execute_input": "2024-09-03T10:15:50.535015Z",
          "iopub.status.idle": "2024-09-03T10:15:50.543257Z",
          "shell.execute_reply.started": "2024-09-03T10:15:50.534969Z",
          "shell.execute_reply": "2024-09-03T10:15:50.542381Z"
        },
        "trusted": true,
        "id": "bW4ieIJZajrM",
        "outputId": "3e0c8605-0afd-4467-db1f-47da7e1dc8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 130,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"i n   t h e   h y d r o x y e t h y l   s t a r c h   g r o u p   a n d   t h e   l a c t a t e d   r i n g e r   ' s   g r o u p   ,   t h e   p a t i e n t s   r e c e i v e d   a n   i n f u s i o n   o f   @   m l   o f   @   %   h y d r o x y e t h y l   s t a r c h   s o l u t i o n   o r   @   m l   o f   l a c t a t e d   r i n g e r   ' s   s o l u t i o n   o v e r   @   m i n   a f t e r   t h e   s p i n a l   b l o c k   .\""
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split sequence-level data splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars = [split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars = [split_chars(sentence) for sentence in test_sentences]\n",
        "print(train_chars[0])# Split sequence-level data splits into character-level data splits"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:15:50.544442Z",
          "iopub.execute_input": "2024-09-03T10:15:50.544739Z",
          "iopub.status.idle": "2024-09-03T10:16:07.337418Z",
          "shell.execute_reply.started": "2024-09-03T10:15:50.544702Z",
          "shell.execute_reply": "2024-09-03T10:16:07.336412Z"
        },
        "trusted": true,
        "id": "W74Pw-kMajrN",
        "outputId": "da4543ce-833e-42e2-82af-846dd0edf141"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "t h e   e m e r g e n c e   o f   h i v   a s   a   c h r o n i c   c o n d i t i o n   m e a n s   t h a t   p e o p l e   l i v i n g   w i t h   h i v   a r e   r e q u i r e d   t o   t a k e   m o r e   r e s p o n s i b i l i t y   f o r   t h e   s e l f - m a n a g e m e n t   o f   t h e i r   c o n d i t i o n   ,   i n c l u d i n g   m a k i n g   p h y s i c a l   ,   e m o t i o n a l   a n d   s o c i a l   a d j u s t m e n t s   .\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What's the average character length?\n",
        "char_lens = [len(sentence) for sentence in train_sentences]\n",
        "mean_char_len = np.mean(char_lens)\n",
        "mean_char_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:16:07.338669Z",
          "iopub.execute_input": "2024-09-03T10:16:07.338997Z",
          "iopub.status.idle": "2024-09-03T10:16:07.920639Z",
          "shell.execute_reply.started": "2024-09-03T10:16:07.338963Z",
          "shell.execute_reply": "2024-09-03T10:16:07.919701Z"
        },
        "trusted": true,
        "id": "tDKUprERajrN",
        "outputId": "e3cb4d86-ab2d-4561-efcb-3ed2ee3fc487"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 132,
          "output_type": "execute_result",
          "data": {
            "text/plain": "147.82646377869133"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the distribution of our sequences at character-level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=7);"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:16:07.921685Z",
          "iopub.execute_input": "2024-09-03T10:16:07.921992Z",
          "iopub.status.idle": "2024-09-03T10:16:16.585671Z",
          "shell.execute_reply.started": "2024-09-03T10:16:07.921955Z",
          "shell.execute_reply": "2024-09-03T10:16:16.584709Z"
        },
        "trusted": true,
        "id": "DCU-4so7ajrN",
        "outputId": "d5e012e6-23b6-47ef-a6bd-a29fa110b142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 640x480 with 1 Axes>",
            "image/png": "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"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:16:16.587209Z",
          "iopub.execute_input": "2024-09-03T10:16:16.58764Z",
          "iopub.status.idle": "2024-09-03T10:16:16.791635Z",
          "shell.execute_reply.started": "2024-09-03T10:16:16.587593Z",
          "shell.execute_reply": "2024-09-03T10:16:16.790014Z"
        },
        "trusted": true,
        "id": "Q3087OlcajrN",
        "outputId": "2768add5-5325-41fd-a545-a267e1bbd11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 134,
          "output_type": "execute_result",
          "data": {
            "text/plain": "284"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all keyboard characters for char-level embedding\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits + string.punctuation\n",
        "alphabet"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:16:16.793139Z",
          "iopub.execute_input": "2024-09-03T10:16:16.793548Z",
          "iopub.status.idle": "2024-09-03T10:16:16.800026Z",
          "shell.execute_reply.started": "2024-09-03T10:16:16.793501Z",
          "shell.execute_reply": "2024-09-03T10:16:16.799064Z"
        },
        "trusted": true,
        "id": "o1JIjS1WajrN",
        "outputId": "54eb734a-9cf1-486e-e3fb-9adb26e3837f"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 135,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char-level token vectorizer instance\n",
        "NUM_CHAR_TOKENS = len(alphabet) + 2 # num characters in alphabet + space + OOV token\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    standardize=\"lower_and_strip_punctuation\",\n",
        "                                    name=\"char_vectorizer\")\n",
        "\n",
        "# Adapt character vectorizer to training characters\n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-03T10:16:16.801537Z",
          "iopub.execute_input": "2024-09-03T10:16:16.802081Z"
        },
        "trusted": true,
        "id": "47bVcHgiajrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check character vocabulary characteristics\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters: {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "SLAEXvvEajrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out character vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n{random_train_chars}\")\n",
        "print(f\"\\nLength of chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n{vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "B2UPLN6LajrN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=NUM_CHAR_TOKENS, # number of different characters\n",
        "                              output_dim=25, # embedding dimension of each character (same as Figure 1 in https://arxiv.org/pdf/1612.05251.pdf)\n",
        "                              mask_zero=False, # don't use masks (this messes up model_5 if set to True)\n",
        "                              name=\"char_embed\")\n",
        "\n",
        "# Test out character embedding layer\n",
        "print(f\"Charified text (before vectorization and embedding):\\n{random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n{char_embed_example}\\n\")\n",
        "print(f\"Character embedding shape: {char_embed_example.shape}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "qUmlLk3_ajrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Combine chars and tokens into a dataset for training\n",
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars))  # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot)  # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels))  # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Repeat the same steps for validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "Y8BXW-x8ajrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_char_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "clgWBj5CajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Setup char inputs/model\n",
        "char_inputs = layers.Input(shape=(1,), dtype=tf.string, name=\"char_input\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(25))(char_embeddings) # bi-LSTM shown in Figure 1 of https://arxiv.org/pdf/1612.05251.pdf\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)"
      ],
      "metadata": {
        "trusted": true,
        "id": "ny42TLQ0ajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_char_token_data = tf.data.Dataset.from_tensor_slices((train_sentences, train_chars)) # make data\n",
        "train_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # make labels\n",
        "train_char_token_dataset = tf.data.Dataset.zip((train_char_token_data, train_char_token_labels)) # combine data and labels\n",
        "\n",
        "# Prefetch and batch train data\n",
        "train_char_token_dataset = train_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Repeat same steps validation data\n",
        "val_char_token_data = tf.data.Dataset.from_tensor_slices((val_sentences, val_chars))\n",
        "val_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_char_token_dataset = tf.data.Dataset.zip((val_char_token_data, val_char_token_labels))\n",
        "val_char_token_dataset = val_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "trusted": true,
        "id": "tRM1KvYaajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"line_number\" column\n",
        "train_line_numbers_one_hot = tf.one_hot(train_df[\"line_number\"].to_numpy(), depth=15)\n",
        "val_line_numbers_one_hot = tf.one_hot(val_df[\"line_number\"].to_numpy(), depth=15)\n",
        "test_line_numbers_one_hot = tf.one_hot(test_df[\"line_number\"].to_numpy(), depth=15)"
      ],
      "metadata": {
        "trusted": true,
        "id": "9NiUiZj1ajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use TensorFlow to create one-hot-encoded tensors of our \"total_lines\" column\n",
        "train_total_lines_one_hot = tf.one_hot(train_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "val_total_lines_one_hot = tf.one_hot(val_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "test_total_lines_one_hot = tf.one_hot(test_df[\"total_lines\"].to_numpy(), depth=20)\n",
        "\n",
        "# Check shape and samples of total lines one-hot tensor\n",
        "train_total_lines_one_hot.shape, train_total_lines_one_hot[:10]\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "p5aopTr-ajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Initialize the Universal Sentence Encoder from TensorFlow Hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\n",
        "    \"https://tfhub.dev/google/universal-sentence-encoder/4\",  # Ensure the URL is correct for your use case\n",
        "    input_shape=[],  # Define input shape as scalar (single string)\n",
        "    dtype=tf.string,  # Ensure input type is string\n",
        "    trainable=False,  # Set to True if you want to fine-tune the embeddings\n",
        "    name=\"universal_sentence_encoder\"\n",
        ")\n",
        "\n",
        "# Define the input layer for tokens\n",
        "input_layer = layers.Input(shape=(), dtype=tf.string, name=\"token_input\")\n",
        "\n",
        "# Wrap the TensorFlow Hub layer in a Lambda layer to handle the KerasTensor\n",
        "token_embeddings = layers.Lambda(lambda x: tf_hub_embedding_layer(tf.cast(x, dtype=tf.string)))(input_layer)\n",
        "\n",
        "# Add a dense layer\n",
        "token_output = layers.Dense(256, activation=\"relu\")(token_embeddings)\n",
        "\n",
        "# Build the model\n",
        "token_model = tf.keras.Model(inputs=input_layer, outputs=token_output)\n",
        "\n",
        "# Print the model summary\n",
        "token_model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "kZ6F2PbRajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Char inputs\n",
        "char_inputs = layers.Input(shape=(1,), dtype=\"string\", name=\"char_inputs\")\n",
        "char_vectors = char_vectorizer(char_inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "char_bi_lstm = layers.Bidirectional(layers.LSTM(64))(char_embeddings)\n",
        "char_model = tf.keras.Model(inputs=char_inputs,\n",
        "                            outputs=char_bi_lstm)"
      ],
      "metadata": {
        "trusted": true,
        "id": "xx2mClpIajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Line numbers inputs\n",
        "line_number_inputs = layers.Input(shape=(15,), dtype=tf.int32, name=\"line_number_input\")\n",
        "x = layers.Dense(64, activation=\"relu\")(line_number_inputs)\n",
        "line_number_model = tf.keras.Model(inputs=line_number_inputs,\n",
        "                                   outputs=x)"
      ],
      "metadata": {
        "trusted": true,
        "id": "S1OpgE56ajrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Total lines inputs\n",
        "total_lines_inputs = layers.Input(shape=(20,), dtype=tf.int32, name=\"total_lines_input\")\n",
        "y = layers.Dense(64, activation=\"relu\")(total_lines_inputs)\n",
        "total_line_model = tf.keras.Model(inputs=total_lines_inputs,\n",
        "                                  outputs=y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "zc7U7Zj7ajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Combine token and char embeddings into a hybrid embedding\n",
        "combined_embeddings = layers.Concatenate(name=\"token_char_hybrid_embedding\")([token_model.output,\n",
        "                                                                              char_model.output])"
      ],
      "metadata": {
        "trusted": true,
        "id": "aJf6VWO4ajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = layers.Dense(512, activation=\"relu\")(combined_embeddings)\n",
        "z = layers.Dropout(0.5)(z)\n",
        "\n",
        "# 6. Combine positional embeddings with combined token and char embeddings into a tribrid embedding\n",
        "z = layers.Concatenate(name=\"token_char_positional_embedding\")([line_number_model.output,\n",
        "                                                                total_line_model.output,\n",
        "                                                                z])\n",
        "\n",
        "# 7. Create output layer\n",
        "output_layer = layers.Dense(5, activation=\"softmax\", name=\"output_layer\")(z)\n",
        "\n",
        "# 8. Put together model\n",
        "model_5 = tf.keras.Model(inputs=[line_number_model.input,\n",
        "                                 total_line_model.input,\n",
        "                                 token_model.input,\n",
        "                                 char_model.input],\n",
        "                         outputs=output_layer)"
      ],
      "metadata": {
        "trusted": true,
        "id": "o4n-q4MgajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ui_fDYerajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.compile(loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.2), # add label smoothing (examples which are really confident get smoothed a little)\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "trusted": true,
        "id": "zAw-aWAIajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation datasets (all four kinds of inputs)\n",
        "train_pos_char_token_data = tf.data.Dataset.from_tensor_slices((train_line_numbers_one_hot, # line numbers\n",
        "                                                                train_total_lines_one_hot, # total lines\n",
        "                                                                train_sentences, # train tokens\n",
        "                                                                train_chars)) # train chars\n",
        "train_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(train_labels_one_hot) # train labels\n",
        "train_pos_char_token_dataset = tf.data.Dataset.zip((train_pos_char_token_data, train_pos_char_token_labels)) # combine data and labels\n",
        "train_pos_char_token_dataset = train_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Validation dataset\n",
        "val_pos_char_token_data = tf.data.Dataset.from_tensor_slices((val_line_numbers_one_hot,\n",
        "                                                              val_total_lines_one_hot,\n",
        "                                                              val_sentences,\n",
        "                                                              val_chars))\n",
        "val_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(val_labels_one_hot)\n",
        "val_pos_char_token_dataset = tf.data.Dataset.zip((val_pos_char_token_data, val_pos_char_token_labels))\n",
        "val_pos_char_token_dataset = val_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE) # turn into batches and prefetch appropriately\n",
        "\n",
        "# Check input shapes\n",
        "train_pos_char_token_dataset, val_pos_char_token_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "ep7y-kMrajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the token, char and positional embedding model\n",
        "history_model_5 = model_5.fit(train_pos_char_token_dataset,\n",
        "                              steps_per_epoch=int(0.1 * len(train_pos_char_token_dataset)),\n",
        "                              epochs=10,\n",
        "                              validation_data=val_pos_char_token_dataset,\n",
        "                              validation_steps=int(0.1 * len(val_pos_char_token_dataset)))"
      ],
      "metadata": {
        "trusted": true,
        "id": "upcetKA_ajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with token-char-positional hybrid model\n",
        "model_5_pred_probs = model_5.predict(val_pos_char_token_dataset, verbose=1)\n",
        "model_5_pred_probs"
      ],
      "metadata": {
        "trusted": true,
        "id": "4e4lF-_sajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into prediction classes\n",
        "model_5_preds = tf.argmax(model_5_pred_probs, axis=1)\n",
        "model_5_preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "NrR0UaugajrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate results of token-char-positional hybrid model\n",
        "model_5_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "trusted": true,
        "id": "5em4MEQIajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create test dataset batch and prefetched\n",
        "test_pos_char_token_data = tf.data.Dataset.from_tensor_slices((test_line_numbers_one_hot,\n",
        "                                                               test_total_lines_one_hot,\n",
        "                                                               test_sentences,\n",
        "                                                               test_chars))\n",
        "test_pos_char_token_labels = tf.data.Dataset.from_tensor_slices(test_labels_one_hot)\n",
        "test_pos_char_token_dataset = tf.data.Dataset.zip((test_pos_char_token_data, test_pos_char_token_labels))\n",
        "test_pos_char_token_dataset = test_pos_char_token_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Check shapes\n",
        "test_pos_char_token_dataset"
      ],
      "metadata": {
        "trusted": true,
        "id": "jHYVCbHoajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_probs = model_5.predict(test_pos_char_token_dataset,\n",
        "                                       verbose=1)\n",
        "test_preds = tf.argmax(test_pred_probs, axis=1)\n",
        "test_preds[:10]"
      ],
      "metadata": {
        "trusted": true,
        "id": "TvacW8zIajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_classes = [label_encoder.classes_[pred] for pred in test_preds]\n",
        "test_pred_classes"
      ],
      "metadata": {
        "trusted": true,
        "id": "OiJtVVHLajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create prediction-enriched test dataframe\n",
        "test_df[\"prediction\"] = test_pred_classes # create column with test prediction class names\n",
        "test_df[\"pred_prob\"] = tf.reduce_max(test_pred_probs, axis=1).numpy() # get the maximum prediction probability\n",
        "test_df[\"correct\"] = test_df[\"prediction\"] == test_df[\"target\"] # create binary column for whether the prediction is right or not\n",
        "test_df.head(20)"
      ],
      "metadata": {
        "trusted": true,
        "id": "klQt7YHXajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find top 100 most wrong samples (note: 100 is an abitrary number, you could go through all of them if you wanted)\n",
        "top_100_wrong = test_df[test_df[\"correct\"] == False].sort_values(\"pred_prob\", ascending=False)[:100]\n",
        "top_100_wrong"
      ],
      "metadata": {
        "trusted": true,
        "id": "PPjtDcRjajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Investigate top wrong preds\n",
        "for row in top_100_wrong[0:10].itertuples(): # adjust indexes to view different samples\n",
        "  _, target, text, line_number, total_lines, prediction, pred_prob, _ = row\n",
        "  print(f\"Target: {target}, Pred: {prediction}, Prob: {pred_prob}, Line number: {line_number}, Total lines: {total_lines}\\n\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"-----\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "-UEfjFT0ajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Download and open example abstracts (copy and pasted from PubMed)\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/skimlit_example_abstracts.json\n",
        "\n",
        "with open(\"skimlit_example_abstracts.json\", \"r\") as f:\n",
        "  example_abstracts = json.load(f)\n",
        "\n",
        "example_abstracts"
      ],
      "metadata": {
        "trusted": true,
        "id": "4YXoRMCGajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See what our example abstracts look like\n",
        "abstracts = pd.DataFrame(example_abstracts)\n",
        "abstracts"
      ],
      "metadata": {
        "trusted": true,
        "id": "y7YiUPtPajrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sentencizer - Source: https://spacy.io/usage/linguistic-features#sbd\n",
        "from spacy.lang.en import English\n",
        "nlp = English() # setup English sentence parser\n",
        "\n",
        "# New version of spaCy\n",
        "sentencizer = nlp.add_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "\n",
        "# Old version of spaCy\n",
        "# sentencizer = nlp.create_pipe(\"sentencizer\") # create sentence splitting pipeline object\n",
        "# nlp.add_pipe(sentencizer) # add sentence splitting pipeline object to sentence parser\n",
        "\n",
        "# Create \"doc\" of parsed sequences, change index for a different abstract\n",
        "doc = nlp(example_abstracts[0][\"abstract\"])\n",
        "abstract_lines = [str(sent) for sent in list(doc.sents)] # return detected sentences from doc in string type (not spaCy token type)\n",
        "abstract_lines"
      ],
      "metadata": {
        "trusted": true,
        "id": "mHo_EUW3ajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get total number of lines\n",
        "total_lines_in_sample = len(abstract_lines)\n",
        "\n",
        "# Go through each line in abstract and create a list of dictionaries containing features for each line\n",
        "sample_lines = []\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  sample_dict = {}\n",
        "  sample_dict[\"text\"] = str(line)\n",
        "  sample_dict[\"line_number\"] = i\n",
        "  sample_dict[\"total_lines\"] = total_lines_in_sample - 1\n",
        "  sample_lines.append(sample_dict)\n",
        "sample_lines"
      ],
      "metadata": {
        "trusted": true,
        "id": "lc-NAbwTajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all line_number values from sample abstract\n",
        "test_abstract_line_numbers = [line[\"line_number\"] for line in sample_lines]\n",
        "# One-hot encode to same depth as training data, so model accepts right input shape\n",
        "test_abstract_line_numbers_one_hot = tf.one_hot(test_abstract_line_numbers, depth=15)\n",
        "test_abstract_line_numbers_one_hot"
      ],
      "metadata": {
        "trusted": true,
        "id": "5IuhB_J6ajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all total_lines values from sample abstract\n",
        "test_abstract_total_lines = [line[\"total_lines\"] for line in sample_lines]\n",
        "# One-hot encode to same depth as training data, so model accepts right input shape\n",
        "test_abstract_total_lines_one_hot = tf.one_hot(test_abstract_total_lines, depth=20)\n",
        "test_abstract_total_lines_one_hot"
      ],
      "metadata": {
        "trusted": true,
        "id": "0ZPTvhyTajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split abstract lines into characters\n",
        "abstract_chars = [split_chars(sentence) for sentence in abstract_lines]\n",
        "abstract_chars"
      ],
      "metadata": {
        "trusted": true,
        "id": "o5JBpBq4ajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on sample abstract features\n",
        "\n",
        "test_abstract_pred_probs = model_5.predict(x=(test_abstract_line_numbers_one_hot,\n",
        "                                                   test_abstract_total_lines_one_hot,\n",
        "                                                   tf.constant(abstract_lines),\n",
        "                                                   tf.constant(abstract_chars)))\n",
        "test_abstract_pred_probs"
      ],
      "metadata": {
        "trusted": true,
        "id": "mes1i95iajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_abstract_preds = tf.argmax(test_abstract_pred_probs, axis=1)\n",
        "test_abstract_preds"
      ],
      "metadata": {
        "trusted": true,
        "id": "gns9RKmCajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction class integers into string class names\n",
        "test_abstract_pred_classes = [label_encoder.classes_[i] for i in test_abstract_preds]\n",
        "test_abstract_pred_classes"
      ],
      "metadata": {
        "trusted": true,
        "id": "ffszkhxuajrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize abstract lines and predicted sequence labels\n",
        "for i, line in enumerate(abstract_lines):\n",
        "  print(f\"{test_abstract_pred_classes[i]}: {line}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "DPLGPIkAajrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pXemDv4LajrW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}